{"ast":null,"code":"/* eslint-disable no-fallthrough */\nimport { UTF16ToUTF8 } from './common';\n/*\n * +----------------------------------------------------------------------------------+\n * | murmurHash3.js v3.0.0 (http://github.com/karanlyons/murmurHash3.js)              |\n * | A TypeScript/JavaScript implementation of MurmurHash3's hashing algorithms.      |\n * |----------------------------------------------------------------------------------|\n * | Copyright (c) 2012-2020 Karan Lyons. Freely distributable under the MIT license. |\n * +----------------------------------------------------------------------------------+\n */\n// PRIVATE FUNCTIONS\n// -----------------\nfunction _x64Add(m, n) {\n  //\n  // Given two 64bit ints (as an array of two 32bit ints) returns the two\n  // added together as a 64bit int (as an array of two 32bit ints).\n  //\n  m = [m[0] >>> 16, m[0] & 0xffff, m[1] >>> 16, m[1] & 0xffff];\n  n = [n[0] >>> 16, n[0] & 0xffff, n[1] >>> 16, n[1] & 0xffff];\n  var o = [0, 0, 0, 0];\n  o[3] += m[3] + n[3];\n  o[2] += o[3] >>> 16;\n  o[3] &= 0xffff;\n  o[2] += m[2] + n[2];\n  o[1] += o[2] >>> 16;\n  o[2] &= 0xffff;\n  o[1] += m[1] + n[1];\n  o[0] += o[1] >>> 16;\n  o[1] &= 0xffff;\n  o[0] += m[0] + n[0];\n  o[0] &= 0xffff;\n  return [o[0] << 16 | o[1], o[2] << 16 | o[3]];\n}\nfunction _x64Multiply(m, n) {\n  //\n  // Given two 64bit ints (as an array of two 32bit ints) returns the two\n  // multiplied together as a 64bit int (as an array of two 32bit ints).\n  //\n  m = [m[0] >>> 16, m[0] & 0xffff, m[1] >>> 16, m[1] & 0xffff];\n  n = [n[0] >>> 16, n[0] & 0xffff, n[1] >>> 16, n[1] & 0xffff];\n  var o = [0, 0, 0, 0];\n  o[3] += m[3] * n[3];\n  o[2] += o[3] >>> 16;\n  o[3] &= 0xffff;\n  o[2] += m[2] * n[3];\n  o[1] += o[2] >>> 16;\n  o[2] &= 0xffff;\n  o[2] += m[3] * n[2];\n  o[1] += o[2] >>> 16;\n  o[2] &= 0xffff;\n  o[1] += m[1] * n[3];\n  o[0] += o[1] >>> 16;\n  o[1] &= 0xffff;\n  o[1] += m[2] * n[2];\n  o[0] += o[1] >>> 16;\n  o[1] &= 0xffff;\n  o[1] += m[3] * n[1];\n  o[0] += o[1] >>> 16;\n  o[1] &= 0xffff;\n  o[0] += m[0] * n[3] + m[1] * n[2] + m[2] * n[1] + m[3] * n[0];\n  o[0] &= 0xffff;\n  return [o[0] << 16 | o[1], o[2] << 16 | o[3]];\n}\nfunction _x64Rotl(m, n) {\n  //\n  // Given a 64bit int (as an array of two 32bit ints) and an int\n  // representing a number of bit positions, returns the 64bit int (as an\n  // array of two 32bit ints) rotated left by that number of positions.\n  //\n  n %= 64;\n  if (n === 32) {\n    return [m[1], m[0]];\n  } else if (n < 32) {\n    return [m[0] << n | m[1] >>> 32 - n, m[1] << n | m[0] >>> 32 - n];\n  } else {\n    n -= 32;\n    return [m[1] << n | m[0] >>> 32 - n, m[0] << n | m[1] >>> 32 - n];\n  }\n}\nfunction _x64LeftShift(m, n) {\n  //\n  // Given a 64bit int (as an array of two 32bit ints) and an int\n  // representing a number of bit positions, returns the 64bit int (as an\n  // array of two 32bit ints) shifted left by that number of positions.\n  //\n  n %= 64;\n  if (n === 0) {\n    return m;\n  } else if (n < 32) {\n    return [m[0] << n | m[1] >>> 32 - n, m[1] << n];\n  } else {\n    return [m[1] << n - 32, 0];\n  }\n}\nfunction _x64Xor(m, n) {\n  //\n  // Given two 64bit ints (as an array of two 32bit ints) returns the two\n  // xored together as a 64bit int (as an array of two 32bit ints).\n  //\n  return [m[0] ^ n[0], m[1] ^ n[1]];\n}\nfunction _x64Fmix(h) {\n  //\n  // Given a block, returns murmurHash3's final x64 mix of that block.\n  // (`[0, h[0] >>> 1]` is a 33 bit unsigned right shift. This is the\n  // only place where we need to right shift 64bit ints.)\n  //\n  h = _x64Xor(h, [0, h[0] >>> 1]);\n  h = _x64Multiply(h, [0xff51afd7, 0xed558ccd]);\n  h = _x64Xor(h, [0, h[0] >>> 1]);\n  h = _x64Multiply(h, [0xc4ceb9fe, 0x1a85ec53]);\n  h = _x64Xor(h, [0, h[0] >>> 1]);\n  return h;\n}\n// PUBLIC FUNCTIONS\n// ----------------\nfunction hash128x64(key, seed) {\n  //\n  // Given a string and an optional seed as an int, returns a 128 bit\n  // hash using the x64 flavor of MurmurHash3, as an unsigned hex.\n  //\n  key = key || '';\n  seed = seed || 0;\n  var remainder = key.length % 16;\n  var bytes = key.length - remainder;\n  var h1 = [0, seed];\n  var h2 = [0, seed];\n  var k1 = [0, 0];\n  var k2 = [0, 0];\n  var c1 = [0x87c37b91, 0x114253d5];\n  var c2 = [0x4cf5ad43, 0x2745937f];\n  for (var i = 0; i < bytes; i = i + 16) {\n    k1 = [key.charCodeAt(i + 4) & 0xff | (key.charCodeAt(i + 5) & 0xff) << 8 | (key.charCodeAt(i + 6) & 0xff) << 16 | (key.charCodeAt(i + 7) & 0xff) << 24, key.charCodeAt(i) & 0xff | (key.charCodeAt(i + 1) & 0xff) << 8 | (key.charCodeAt(i + 2) & 0xff) << 16 | (key.charCodeAt(i + 3) & 0xff) << 24];\n    k2 = [key.charCodeAt(i + 12) & 0xff | (key.charCodeAt(i + 13) & 0xff) << 8 | (key.charCodeAt(i + 14) & 0xff) << 16 | (key.charCodeAt(i + 15) & 0xff) << 24, key.charCodeAt(i + 8) & 0xff | (key.charCodeAt(i + 9) & 0xff) << 8 | (key.charCodeAt(i + 10) & 0xff) << 16 | (key.charCodeAt(i + 11) & 0xff) << 24];\n    k1 = _x64Multiply(k1, c1);\n    k1 = _x64Rotl(k1, 31);\n    k1 = _x64Multiply(k1, c2);\n    h1 = _x64Xor(h1, k1);\n    h1 = _x64Rotl(h1, 27);\n    h1 = _x64Add(h1, h2);\n    h1 = _x64Add(_x64Multiply(h1, [0, 5]), [0, 0x52dce729]);\n    k2 = _x64Multiply(k2, c2);\n    k2 = _x64Rotl(k2, 33);\n    k2 = _x64Multiply(k2, c1);\n    h2 = _x64Xor(h2, k2);\n    h2 = _x64Rotl(h2, 31);\n    h2 = _x64Add(h2, h1);\n    h2 = _x64Add(_x64Multiply(h2, [0, 5]), [0, 0x38495ab5]);\n  }\n  k1 = [0, 0];\n  k2 = [0, 0];\n  switch (remainder) {\n    case 15:\n      k2 = _x64Xor(k2, _x64LeftShift([0, key.charCodeAt(i + 14)], 48));\n    case 14:\n      k2 = _x64Xor(k2, _x64LeftShift([0, key.charCodeAt(i + 13)], 40));\n    case 13:\n      k2 = _x64Xor(k2, _x64LeftShift([0, key.charCodeAt(i + 12)], 32));\n    case 12:\n      k2 = _x64Xor(k2, _x64LeftShift([0, key.charCodeAt(i + 11)], 24));\n    case 11:\n      k2 = _x64Xor(k2, _x64LeftShift([0, key.charCodeAt(i + 10)], 16));\n    case 10:\n      k2 = _x64Xor(k2, _x64LeftShift([0, key.charCodeAt(i + 9)], 8));\n    case 9:\n      k2 = _x64Xor(k2, [0, key.charCodeAt(i + 8)]);\n      k2 = _x64Multiply(k2, c2);\n      k2 = _x64Rotl(k2, 33);\n      k2 = _x64Multiply(k2, c1);\n      h2 = _x64Xor(h2, k2);\n    case 8:\n      k1 = _x64Xor(k1, _x64LeftShift([0, key.charCodeAt(i + 7)], 56));\n    case 7:\n      k1 = _x64Xor(k1, _x64LeftShift([0, key.charCodeAt(i + 6)], 48));\n    case 6:\n      k1 = _x64Xor(k1, _x64LeftShift([0, key.charCodeAt(i + 5)], 40));\n    case 5:\n      k1 = _x64Xor(k1, _x64LeftShift([0, key.charCodeAt(i + 4)], 32));\n    case 4:\n      k1 = _x64Xor(k1, _x64LeftShift([0, key.charCodeAt(i + 3)], 24));\n    case 3:\n      k1 = _x64Xor(k1, _x64LeftShift([0, key.charCodeAt(i + 2)], 16));\n    case 2:\n      k1 = _x64Xor(k1, _x64LeftShift([0, key.charCodeAt(i + 1)], 8));\n    case 1:\n      k1 = _x64Xor(k1, [0, key.charCodeAt(i)]);\n      k1 = _x64Multiply(k1, c1);\n      k1 = _x64Rotl(k1, 31);\n      k1 = _x64Multiply(k1, c2);\n      h1 = _x64Xor(h1, k1);\n  }\n  h1 = _x64Xor(h1, [0, key.length]);\n  h2 = _x64Xor(h2, [0, key.length]);\n  h1 = _x64Add(h1, h2);\n  h2 = _x64Add(h2, h1);\n  h1 = _x64Fmix(h1);\n  h2 = _x64Fmix(h2);\n  h1 = _x64Add(h1, h2);\n  h2 = _x64Add(h2, h1);\n  return ('00000000' + (h1[0] >>> 0).toString(16)).slice(-8) + ('00000000' + (h1[1] >>> 0).toString(16)).slice(-8) + ('00000000' + (h2[0] >>> 0).toString(16)).slice(-8) + ('00000000' + (h2[1] >>> 0).toString(16)).slice(-8);\n}\n/**\n * x64 version of Murmur3 for 128bits.\n *\n * @param {string} str\n */\nexport function hash128(str, seed) {\n  return hash128x64(UTF16ToUTF8(str), seed >>> 0);\n}","map":{"version":3,"names":["UTF16ToUTF8","_x64Add","m","n","o","_x64Multiply","_x64Rotl","_x64LeftShift","_x64Xor","_x64Fmix","h","hash128x64","key","seed","remainder","length","bytes","h1","h2","k1","k2","c1","c2","i","charCodeAt","toString","slice","hash128","str"],"sources":["/Users/temitopeogunrekun/Desktop/angular-db/node_modules/@splitsoftware/splitio-commons/esm/utils/murmur3/murmur3_128.js"],"sourcesContent":["/* eslint-disable no-fallthrough */\nimport { UTF16ToUTF8 } from './common';\n/*\n * +----------------------------------------------------------------------------------+\n * | murmurHash3.js v3.0.0 (http://github.com/karanlyons/murmurHash3.js)              |\n * | A TypeScript/JavaScript implementation of MurmurHash3's hashing algorithms.      |\n * |----------------------------------------------------------------------------------|\n * | Copyright (c) 2012-2020 Karan Lyons. Freely distributable under the MIT license. |\n * +----------------------------------------------------------------------------------+\n */\n// PRIVATE FUNCTIONS\n// -----------------\nfunction _x64Add(m, n) {\n    //\n    // Given two 64bit ints (as an array of two 32bit ints) returns the two\n    // added together as a 64bit int (as an array of two 32bit ints).\n    //\n    m = [m[0] >>> 16, m[0] & 0xffff, m[1] >>> 16, m[1] & 0xffff];\n    n = [n[0] >>> 16, n[0] & 0xffff, n[1] >>> 16, n[1] & 0xffff];\n    var o = [0, 0, 0, 0];\n    o[3] += m[3] + n[3];\n    o[2] += o[3] >>> 16;\n    o[3] &= 0xffff;\n    o[2] += m[2] + n[2];\n    o[1] += o[2] >>> 16;\n    o[2] &= 0xffff;\n    o[1] += m[1] + n[1];\n    o[0] += o[1] >>> 16;\n    o[1] &= 0xffff;\n    o[0] += m[0] + n[0];\n    o[0] &= 0xffff;\n    return [(o[0] << 16) | o[1], (o[2] << 16) | o[3]];\n}\nfunction _x64Multiply(m, n) {\n    //\n    // Given two 64bit ints (as an array of two 32bit ints) returns the two\n    // multiplied together as a 64bit int (as an array of two 32bit ints).\n    //\n    m = [m[0] >>> 16, m[0] & 0xffff, m[1] >>> 16, m[1] & 0xffff];\n    n = [n[0] >>> 16, n[0] & 0xffff, n[1] >>> 16, n[1] & 0xffff];\n    var o = [0, 0, 0, 0];\n    o[3] += m[3] * n[3];\n    o[2] += o[3] >>> 16;\n    o[3] &= 0xffff;\n    o[2] += m[2] * n[3];\n    o[1] += o[2] >>> 16;\n    o[2] &= 0xffff;\n    o[2] += m[3] * n[2];\n    o[1] += o[2] >>> 16;\n    o[2] &= 0xffff;\n    o[1] += m[1] * n[3];\n    o[0] += o[1] >>> 16;\n    o[1] &= 0xffff;\n    o[1] += m[2] * n[2];\n    o[0] += o[1] >>> 16;\n    o[1] &= 0xffff;\n    o[1] += m[3] * n[1];\n    o[0] += o[1] >>> 16;\n    o[1] &= 0xffff;\n    o[0] += (m[0] * n[3]) + (m[1] * n[2]) + (m[2] * n[1]) + (m[3] * n[0]);\n    o[0] &= 0xffff;\n    return [(o[0] << 16) | o[1], (o[2] << 16) | o[3]];\n}\nfunction _x64Rotl(m, n) {\n    //\n    // Given a 64bit int (as an array of two 32bit ints) and an int\n    // representing a number of bit positions, returns the 64bit int (as an\n    // array of two 32bit ints) rotated left by that number of positions.\n    //\n    n %= 64;\n    if (n === 32) {\n        return [m[1], m[0]];\n    }\n    else if (n < 32) {\n        return [(m[0] << n) | (m[1] >>> (32 - n)), (m[1] << n) | (m[0] >>> (32 - n))];\n    }\n    else {\n        n -= 32;\n        return [(m[1] << n) | (m[0] >>> (32 - n)), (m[0] << n) | (m[1] >>> (32 - n))];\n    }\n}\nfunction _x64LeftShift(m, n) {\n    //\n    // Given a 64bit int (as an array of two 32bit ints) and an int\n    // representing a number of bit positions, returns the 64bit int (as an\n    // array of two 32bit ints) shifted left by that number of positions.\n    //\n    n %= 64;\n    if (n === 0) {\n        return m;\n    }\n    else if (n < 32) {\n        return [(m[0] << n) | (m[1] >>> (32 - n)), m[1] << n];\n    }\n    else {\n        return [m[1] << (n - 32), 0];\n    }\n}\nfunction _x64Xor(m, n) {\n    //\n    // Given two 64bit ints (as an array of two 32bit ints) returns the two\n    // xored together as a 64bit int (as an array of two 32bit ints).\n    //\n    return [m[0] ^ n[0], m[1] ^ n[1]];\n}\nfunction _x64Fmix(h) {\n    //\n    // Given a block, returns murmurHash3's final x64 mix of that block.\n    // (`[0, h[0] >>> 1]` is a 33 bit unsigned right shift. This is the\n    // only place where we need to right shift 64bit ints.)\n    //\n    h = _x64Xor(h, [0, h[0] >>> 1]);\n    h = _x64Multiply(h, [0xff51afd7, 0xed558ccd]);\n    h = _x64Xor(h, [0, h[0] >>> 1]);\n    h = _x64Multiply(h, [0xc4ceb9fe, 0x1a85ec53]);\n    h = _x64Xor(h, [0, h[0] >>> 1]);\n    return h;\n}\n// PUBLIC FUNCTIONS\n// ----------------\nfunction hash128x64(key, seed) {\n    //\n    // Given a string and an optional seed as an int, returns a 128 bit\n    // hash using the x64 flavor of MurmurHash3, as an unsigned hex.\n    //\n    key = key || '';\n    seed = seed || 0;\n    var remainder = key.length % 16;\n    var bytes = key.length - remainder;\n    var h1 = [0, seed];\n    var h2 = [0, seed];\n    var k1 = [0, 0];\n    var k2 = [0, 0];\n    var c1 = [0x87c37b91, 0x114253d5];\n    var c2 = [0x4cf5ad43, 0x2745937f];\n    for (var i = 0; i < bytes; i = i + 16) {\n        k1 = [((key.charCodeAt(i + 4) & 0xff)) | ((key.charCodeAt(i + 5) & 0xff) << 8) | ((key.charCodeAt(i + 6) & 0xff) << 16) | ((key.charCodeAt(i + 7) & 0xff) << 24), ((key.charCodeAt(i) & 0xff)) | ((key.charCodeAt(i + 1) &\n                0xff) << 8) | ((key.charCodeAt(i + 2) & 0xff) << 16) | ((key.charCodeAt(i + 3) & 0xff) << 24)];\n        k2 = [((key.charCodeAt(i + 12) & 0xff)) | ((key.charCodeAt(i + 13) & 0xff) << 8) | ((key.charCodeAt(i + 14) & 0xff) << 16) | ((key.charCodeAt(i + 15) & 0xff) << 24), ((key.charCodeAt(i + 8) & 0xff)) | ((key.charCodeAt(i +\n                9) & 0xff) << 8) | ((key.charCodeAt(i + 10) & 0xff) << 16) | ((key.charCodeAt(i + 11) & 0xff) << 24)];\n        k1 = _x64Multiply(k1, c1);\n        k1 = _x64Rotl(k1, 31);\n        k1 = _x64Multiply(k1, c2);\n        h1 = _x64Xor(h1, k1);\n        h1 = _x64Rotl(h1, 27);\n        h1 = _x64Add(h1, h2);\n        h1 = _x64Add(_x64Multiply(h1, [0, 5]), [0, 0x52dce729]);\n        k2 = _x64Multiply(k2, c2);\n        k2 = _x64Rotl(k2, 33);\n        k2 = _x64Multiply(k2, c1);\n        h2 = _x64Xor(h2, k2);\n        h2 = _x64Rotl(h2, 31);\n        h2 = _x64Add(h2, h1);\n        h2 = _x64Add(_x64Multiply(h2, [0, 5]), [0, 0x38495ab5]);\n    }\n    k1 = [0, 0];\n    k2 = [0, 0];\n    switch (remainder) {\n        case 15:\n            k2 = _x64Xor(k2, _x64LeftShift([0, key.charCodeAt(i + 14)], 48));\n        case 14:\n            k2 = _x64Xor(k2, _x64LeftShift([0, key.charCodeAt(i + 13)], 40));\n        case 13:\n            k2 = _x64Xor(k2, _x64LeftShift([0, key.charCodeAt(i + 12)], 32));\n        case 12:\n            k2 = _x64Xor(k2, _x64LeftShift([0, key.charCodeAt(i + 11)], 24));\n        case 11:\n            k2 = _x64Xor(k2, _x64LeftShift([0, key.charCodeAt(i + 10)], 16));\n        case 10:\n            k2 = _x64Xor(k2, _x64LeftShift([0, key.charCodeAt(i + 9)], 8));\n        case 9:\n            k2 = _x64Xor(k2, [0, key.charCodeAt(i + 8)]);\n            k2 = _x64Multiply(k2, c2);\n            k2 = _x64Rotl(k2, 33);\n            k2 = _x64Multiply(k2, c1);\n            h2 = _x64Xor(h2, k2);\n        case 8:\n            k1 = _x64Xor(k1, _x64LeftShift([0, key.charCodeAt(i + 7)], 56));\n        case 7:\n            k1 = _x64Xor(k1, _x64LeftShift([0, key.charCodeAt(i + 6)], 48));\n        case 6:\n            k1 = _x64Xor(k1, _x64LeftShift([0, key.charCodeAt(i + 5)], 40));\n        case 5:\n            k1 = _x64Xor(k1, _x64LeftShift([0, key.charCodeAt(i + 4)], 32));\n        case 4:\n            k1 = _x64Xor(k1, _x64LeftShift([0, key.charCodeAt(i + 3)], 24));\n        case 3:\n            k1 = _x64Xor(k1, _x64LeftShift([0, key.charCodeAt(i + 2)], 16));\n        case 2:\n            k1 = _x64Xor(k1, _x64LeftShift([0, key.charCodeAt(i + 1)], 8));\n        case 1:\n            k1 = _x64Xor(k1, [0, key.charCodeAt(i)]);\n            k1 = _x64Multiply(k1, c1);\n            k1 = _x64Rotl(k1, 31);\n            k1 = _x64Multiply(k1, c2);\n            h1 = _x64Xor(h1, k1);\n    }\n    h1 = _x64Xor(h1, [0, key.length]);\n    h2 = _x64Xor(h2, [0, key.length]);\n    h1 = _x64Add(h1, h2);\n    h2 = _x64Add(h2, h1);\n    h1 = _x64Fmix(h1);\n    h2 = _x64Fmix(h2);\n    h1 = _x64Add(h1, h2);\n    h2 = _x64Add(h2, h1);\n    return ('00000000' + (h1[0] >>> 0).toString(16)).slice(-8) + ('00000000' + (h1[1] >>> 0).toString(16)).slice(-8) + ('00000000' + (h2[0] >>> 0).toString(16)).slice(-8) + ('00000000' + (h2[1] >>> 0).toString(16)).slice(-8);\n}\n/**\n * x64 version of Murmur3 for 128bits.\n *\n * @param {string} str\n */\nexport function hash128(str, seed) {\n    return hash128x64(UTF16ToUTF8(str), seed >>> 0);\n}\n"],"mappings":"AAAA;AACA,SAASA,WAAW,QAAQ,UAAU;AACtC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAASC,OAAO,CAACC,CAAC,EAAEC,CAAC,EAAE;EACnB;EACA;EACA;EACA;EACAD,CAAC,GAAG,CAACA,CAAC,CAAC,CAAC,CAAC,KAAK,EAAE,EAAEA,CAAC,CAAC,CAAC,CAAC,GAAG,MAAM,EAAEA,CAAC,CAAC,CAAC,CAAC,KAAK,EAAE,EAAEA,CAAC,CAAC,CAAC,CAAC,GAAG,MAAM,CAAC;EAC5DC,CAAC,GAAG,CAACA,CAAC,CAAC,CAAC,CAAC,KAAK,EAAE,EAAEA,CAAC,CAAC,CAAC,CAAC,GAAG,MAAM,EAAEA,CAAC,CAAC,CAAC,CAAC,KAAK,EAAE,EAAEA,CAAC,CAAC,CAAC,CAAC,GAAG,MAAM,CAAC;EAC5D,IAAIC,CAAC,GAAG,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC;EACpBA,CAAC,CAAC,CAAC,CAAC,IAAIF,CAAC,CAAC,CAAC,CAAC,GAAGC,CAAC,CAAC,CAAC,CAAC;EACnBC,CAAC,CAAC,CAAC,CAAC,IAAIA,CAAC,CAAC,CAAC,CAAC,KAAK,EAAE;EACnBA,CAAC,CAAC,CAAC,CAAC,IAAI,MAAM;EACdA,CAAC,CAAC,CAAC,CAAC,IAAIF,CAAC,CAAC,CAAC,CAAC,GAAGC,CAAC,CAAC,CAAC,CAAC;EACnBC,CAAC,CAAC,CAAC,CAAC,IAAIA,CAAC,CAAC,CAAC,CAAC,KAAK,EAAE;EACnBA,CAAC,CAAC,CAAC,CAAC,IAAI,MAAM;EACdA,CAAC,CAAC,CAAC,CAAC,IAAIF,CAAC,CAAC,CAAC,CAAC,GAAGC,CAAC,CAAC,CAAC,CAAC;EACnBC,CAAC,CAAC,CAAC,CAAC,IAAIA,CAAC,CAAC,CAAC,CAAC,KAAK,EAAE;EACnBA,CAAC,CAAC,CAAC,CAAC,IAAI,MAAM;EACdA,CAAC,CAAC,CAAC,CAAC,IAAIF,CAAC,CAAC,CAAC,CAAC,GAAGC,CAAC,CAAC,CAAC,CAAC;EACnBC,CAAC,CAAC,CAAC,CAAC,IAAI,MAAM;EACd,OAAO,CAAEA,CAAC,CAAC,CAAC,CAAC,IAAI,EAAE,GAAIA,CAAC,CAAC,CAAC,CAAC,EAAGA,CAAC,CAAC,CAAC,CAAC,IAAI,EAAE,GAAIA,CAAC,CAAC,CAAC,CAAC,CAAC;AACrD;AACA,SAASC,YAAY,CAACH,CAAC,EAAEC,CAAC,EAAE;EACxB;EACA;EACA;EACA;EACAD,CAAC,GAAG,CAACA,CAAC,CAAC,CAAC,CAAC,KAAK,EAAE,EAAEA,CAAC,CAAC,CAAC,CAAC,GAAG,MAAM,EAAEA,CAAC,CAAC,CAAC,CAAC,KAAK,EAAE,EAAEA,CAAC,CAAC,CAAC,CAAC,GAAG,MAAM,CAAC;EAC5DC,CAAC,GAAG,CAACA,CAAC,CAAC,CAAC,CAAC,KAAK,EAAE,EAAEA,CAAC,CAAC,CAAC,CAAC,GAAG,MAAM,EAAEA,CAAC,CAAC,CAAC,CAAC,KAAK,EAAE,EAAEA,CAAC,CAAC,CAAC,CAAC,GAAG,MAAM,CAAC;EAC5D,IAAIC,CAAC,GAAG,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC;EACpBA,CAAC,CAAC,CAAC,CAAC,IAAIF,CAAC,CAAC,CAAC,CAAC,GAAGC,CAAC,CAAC,CAAC,CAAC;EACnBC,CAAC,CAAC,CAAC,CAAC,IAAIA,CAAC,CAAC,CAAC,CAAC,KAAK,EAAE;EACnBA,CAAC,CAAC,CAAC,CAAC,IAAI,MAAM;EACdA,CAAC,CAAC,CAAC,CAAC,IAAIF,CAAC,CAAC,CAAC,CAAC,GAAGC,CAAC,CAAC,CAAC,CAAC;EACnBC,CAAC,CAAC,CAAC,CAAC,IAAIA,CAAC,CAAC,CAAC,CAAC,KAAK,EAAE;EACnBA,CAAC,CAAC,CAAC,CAAC,IAAI,MAAM;EACdA,CAAC,CAAC,CAAC,CAAC,IAAIF,CAAC,CAAC,CAAC,CAAC,GAAGC,CAAC,CAAC,CAAC,CAAC;EACnBC,CAAC,CAAC,CAAC,CAAC,IAAIA,CAAC,CAAC,CAAC,CAAC,KAAK,EAAE;EACnBA,CAAC,CAAC,CAAC,CAAC,IAAI,MAAM;EACdA,CAAC,CAAC,CAAC,CAAC,IAAIF,CAAC,CAAC,CAAC,CAAC,GAAGC,CAAC,CAAC,CAAC,CAAC;EACnBC,CAAC,CAAC,CAAC,CAAC,IAAIA,CAAC,CAAC,CAAC,CAAC,KAAK,EAAE;EACnBA,CAAC,CAAC,CAAC,CAAC,IAAI,MAAM;EACdA,CAAC,CAAC,CAAC,CAAC,IAAIF,CAAC,CAAC,CAAC,CAAC,GAAGC,CAAC,CAAC,CAAC,CAAC;EACnBC,CAAC,CAAC,CAAC,CAAC,IAAIA,CAAC,CAAC,CAAC,CAAC,KAAK,EAAE;EACnBA,CAAC,CAAC,CAAC,CAAC,IAAI,MAAM;EACdA,CAAC,CAAC,CAAC,CAAC,IAAIF,CAAC,CAAC,CAAC,CAAC,GAAGC,CAAC,CAAC,CAAC,CAAC;EACnBC,CAAC,CAAC,CAAC,CAAC,IAAIA,CAAC,CAAC,CAAC,CAAC,KAAK,EAAE;EACnBA,CAAC,CAAC,CAAC,CAAC,IAAI,MAAM;EACdA,CAAC,CAAC,CAAC,CAAC,IAAKF,CAAC,CAAC,CAAC,CAAC,GAAGC,CAAC,CAAC,CAAC,CAAC,GAAKD,CAAC,CAAC,CAAC,CAAC,GAAGC,CAAC,CAAC,CAAC,CAAE,GAAID,CAAC,CAAC,CAAC,CAAC,GAAGC,CAAC,CAAC,CAAC,CAAE,GAAID,CAAC,CAAC,CAAC,CAAC,GAAGC,CAAC,CAAC,CAAC,CAAE;EACrEC,CAAC,CAAC,CAAC,CAAC,IAAI,MAAM;EACd,OAAO,CAAEA,CAAC,CAAC,CAAC,CAAC,IAAI,EAAE,GAAIA,CAAC,CAAC,CAAC,CAAC,EAAGA,CAAC,CAAC,CAAC,CAAC,IAAI,EAAE,GAAIA,CAAC,CAAC,CAAC,CAAC,CAAC;AACrD;AACA,SAASE,QAAQ,CAACJ,CAAC,EAAEC,CAAC,EAAE;EACpB;EACA;EACA;EACA;EACA;EACAA,CAAC,IAAI,EAAE;EACP,IAAIA,CAAC,KAAK,EAAE,EAAE;IACV,OAAO,CAACD,CAAC,CAAC,CAAC,CAAC,EAAEA,CAAC,CAAC,CAAC,CAAC,CAAC;EACvB,CAAC,MACI,IAAIC,CAAC,GAAG,EAAE,EAAE;IACb,OAAO,CAAED,CAAC,CAAC,CAAC,CAAC,IAAIC,CAAC,GAAKD,CAAC,CAAC,CAAC,CAAC,KAAM,EAAE,GAAGC,CAAG,EAAGD,CAAC,CAAC,CAAC,CAAC,IAAIC,CAAC,GAAKD,CAAC,CAAC,CAAC,CAAC,KAAM,EAAE,GAAGC,CAAG,CAAC;EACjF,CAAC,MACI;IACDA,CAAC,IAAI,EAAE;IACP,OAAO,CAAED,CAAC,CAAC,CAAC,CAAC,IAAIC,CAAC,GAAKD,CAAC,CAAC,CAAC,CAAC,KAAM,EAAE,GAAGC,CAAG,EAAGD,CAAC,CAAC,CAAC,CAAC,IAAIC,CAAC,GAAKD,CAAC,CAAC,CAAC,CAAC,KAAM,EAAE,GAAGC,CAAG,CAAC;EACjF;AACJ;AACA,SAASI,aAAa,CAACL,CAAC,EAAEC,CAAC,EAAE;EACzB;EACA;EACA;EACA;EACA;EACAA,CAAC,IAAI,EAAE;EACP,IAAIA,CAAC,KAAK,CAAC,EAAE;IACT,OAAOD,CAAC;EACZ,CAAC,MACI,IAAIC,CAAC,GAAG,EAAE,EAAE;IACb,OAAO,CAAED,CAAC,CAAC,CAAC,CAAC,IAAIC,CAAC,GAAKD,CAAC,CAAC,CAAC,CAAC,KAAM,EAAE,GAAGC,CAAG,EAAED,CAAC,CAAC,CAAC,CAAC,IAAIC,CAAC,CAAC;EACzD,CAAC,MACI;IACD,OAAO,CAACD,CAAC,CAAC,CAAC,CAAC,IAAKC,CAAC,GAAG,EAAG,EAAE,CAAC,CAAC;EAChC;AACJ;AACA,SAASK,OAAO,CAACN,CAAC,EAAEC,CAAC,EAAE;EACnB;EACA;EACA;EACA;EACA,OAAO,CAACD,CAAC,CAAC,CAAC,CAAC,GAAGC,CAAC,CAAC,CAAC,CAAC,EAAED,CAAC,CAAC,CAAC,CAAC,GAAGC,CAAC,CAAC,CAAC,CAAC,CAAC;AACrC;AACA,SAASM,QAAQ,CAACC,CAAC,EAAE;EACjB;EACA;EACA;EACA;EACA;EACAA,CAAC,GAAGF,OAAO,CAACE,CAAC,EAAE,CAAC,CAAC,EAAEA,CAAC,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC;EAC/BA,CAAC,GAAGL,YAAY,CAACK,CAAC,EAAE,CAAC,UAAU,EAAE,UAAU,CAAC,CAAC;EAC7CA,CAAC,GAAGF,OAAO,CAACE,CAAC,EAAE,CAAC,CAAC,EAAEA,CAAC,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC;EAC/BA,CAAC,GAAGL,YAAY,CAACK,CAAC,EAAE,CAAC,UAAU,EAAE,UAAU,CAAC,CAAC;EAC7CA,CAAC,GAAGF,OAAO,CAACE,CAAC,EAAE,CAAC,CAAC,EAAEA,CAAC,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC;EAC/B,OAAOA,CAAC;AACZ;AACA;AACA;AACA,SAASC,UAAU,CAACC,GAAG,EAAEC,IAAI,EAAE;EAC3B;EACA;EACA;EACA;EACAD,GAAG,GAAGA,GAAG,IAAI,EAAE;EACfC,IAAI,GAAGA,IAAI,IAAI,CAAC;EAChB,IAAIC,SAAS,GAAGF,GAAG,CAACG,MAAM,GAAG,EAAE;EAC/B,IAAIC,KAAK,GAAGJ,GAAG,CAACG,MAAM,GAAGD,SAAS;EAClC,IAAIG,EAAE,GAAG,CAAC,CAAC,EAAEJ,IAAI,CAAC;EAClB,IAAIK,EAAE,GAAG,CAAC,CAAC,EAAEL,IAAI,CAAC;EAClB,IAAIM,EAAE,GAAG,CAAC,CAAC,EAAE,CAAC,CAAC;EACf,IAAIC,EAAE,GAAG,CAAC,CAAC,EAAE,CAAC,CAAC;EACf,IAAIC,EAAE,GAAG,CAAC,UAAU,EAAE,UAAU,CAAC;EACjC,IAAIC,EAAE,GAAG,CAAC,UAAU,EAAE,UAAU,CAAC;EACjC,KAAK,IAAIC,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGP,KAAK,EAAEO,CAAC,GAAGA,CAAC,GAAG,EAAE,EAAE;IACnCJ,EAAE,GAAG,CAAGP,GAAG,CAACY,UAAU,CAACD,CAAC,GAAG,CAAC,CAAC,GAAG,IAAI,GAAM,CAACX,GAAG,CAACY,UAAU,CAACD,CAAC,GAAG,CAAC,CAAC,GAAG,IAAI,KAAK,CAAE,GAAI,CAACX,GAAG,CAACY,UAAU,CAACD,CAAC,GAAG,CAAC,CAAC,GAAG,IAAI,KAAK,EAAG,GAAI,CAACX,GAAG,CAACY,UAAU,CAACD,CAAC,GAAG,CAAC,CAAC,GAAG,IAAI,KAAK,EAAG,EAAIX,GAAG,CAACY,UAAU,CAACD,CAAC,CAAC,GAAG,IAAI,GAAM,CAACX,GAAG,CAACY,UAAU,CAACD,CAAC,GAAG,CAAC,CAAC,GAChN,IAAI,KAAK,CAAE,GAAI,CAACX,GAAG,CAACY,UAAU,CAACD,CAAC,GAAG,CAAC,CAAC,GAAG,IAAI,KAAK,EAAG,GAAI,CAACX,GAAG,CAACY,UAAU,CAACD,CAAC,GAAG,CAAC,CAAC,GAAG,IAAI,KAAK,EAAG,CAAC;IACtGH,EAAE,GAAG,CAAGR,GAAG,CAACY,UAAU,CAACD,CAAC,GAAG,EAAE,CAAC,GAAG,IAAI,GAAM,CAACX,GAAG,CAACY,UAAU,CAACD,CAAC,GAAG,EAAE,CAAC,GAAG,IAAI,KAAK,CAAE,GAAI,CAACX,GAAG,CAACY,UAAU,CAACD,CAAC,GAAG,EAAE,CAAC,GAAG,IAAI,KAAK,EAAG,GAAI,CAACX,GAAG,CAACY,UAAU,CAACD,CAAC,GAAG,EAAE,CAAC,GAAG,IAAI,KAAK,EAAG,EAAIX,GAAG,CAACY,UAAU,CAACD,CAAC,GAAG,CAAC,CAAC,GAAG,IAAI,GAAM,CAACX,GAAG,CAACY,UAAU,CAACD,CAAC,GACnN,CAAC,CAAC,GAAG,IAAI,KAAK,CAAE,GAAI,CAACX,GAAG,CAACY,UAAU,CAACD,CAAC,GAAG,EAAE,CAAC,GAAG,IAAI,KAAK,EAAG,GAAI,CAACX,GAAG,CAACY,UAAU,CAACD,CAAC,GAAG,EAAE,CAAC,GAAG,IAAI,KAAK,EAAG,CAAC;IAC7GJ,EAAE,GAAGd,YAAY,CAACc,EAAE,EAAEE,EAAE,CAAC;IACzBF,EAAE,GAAGb,QAAQ,CAACa,EAAE,EAAE,EAAE,CAAC;IACrBA,EAAE,GAAGd,YAAY,CAACc,EAAE,EAAEG,EAAE,CAAC;IACzBL,EAAE,GAAGT,OAAO,CAACS,EAAE,EAAEE,EAAE,CAAC;IACpBF,EAAE,GAAGX,QAAQ,CAACW,EAAE,EAAE,EAAE,CAAC;IACrBA,EAAE,GAAGhB,OAAO,CAACgB,EAAE,EAAEC,EAAE,CAAC;IACpBD,EAAE,GAAGhB,OAAO,CAACI,YAAY,CAACY,EAAE,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,UAAU,CAAC,CAAC;IACvDG,EAAE,GAAGf,YAAY,CAACe,EAAE,EAAEE,EAAE,CAAC;IACzBF,EAAE,GAAGd,QAAQ,CAACc,EAAE,EAAE,EAAE,CAAC;IACrBA,EAAE,GAAGf,YAAY,CAACe,EAAE,EAAEC,EAAE,CAAC;IACzBH,EAAE,GAAGV,OAAO,CAACU,EAAE,EAAEE,EAAE,CAAC;IACpBF,EAAE,GAAGZ,QAAQ,CAACY,EAAE,EAAE,EAAE,CAAC;IACrBA,EAAE,GAAGjB,OAAO,CAACiB,EAAE,EAAED,EAAE,CAAC;IACpBC,EAAE,GAAGjB,OAAO,CAACI,YAAY,CAACa,EAAE,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,UAAU,CAAC,CAAC;EAC3D;EACAC,EAAE,GAAG,CAAC,CAAC,EAAE,CAAC,CAAC;EACXC,EAAE,GAAG,CAAC,CAAC,EAAE,CAAC,CAAC;EACX,QAAQN,SAAS;IACb,KAAK,EAAE;MACHM,EAAE,GAAGZ,OAAO,CAACY,EAAE,EAAEb,aAAa,CAAC,CAAC,CAAC,EAAEK,GAAG,CAACY,UAAU,CAACD,CAAC,GAAG,EAAE,CAAC,CAAC,EAAE,EAAE,CAAC,CAAC;IACpE,KAAK,EAAE;MACHH,EAAE,GAAGZ,OAAO,CAACY,EAAE,EAAEb,aAAa,CAAC,CAAC,CAAC,EAAEK,GAAG,CAACY,UAAU,CAACD,CAAC,GAAG,EAAE,CAAC,CAAC,EAAE,EAAE,CAAC,CAAC;IACpE,KAAK,EAAE;MACHH,EAAE,GAAGZ,OAAO,CAACY,EAAE,EAAEb,aAAa,CAAC,CAAC,CAAC,EAAEK,GAAG,CAACY,UAAU,CAACD,CAAC,GAAG,EAAE,CAAC,CAAC,EAAE,EAAE,CAAC,CAAC;IACpE,KAAK,EAAE;MACHH,EAAE,GAAGZ,OAAO,CAACY,EAAE,EAAEb,aAAa,CAAC,CAAC,CAAC,EAAEK,GAAG,CAACY,UAAU,CAACD,CAAC,GAAG,EAAE,CAAC,CAAC,EAAE,EAAE,CAAC,CAAC;IACpE,KAAK,EAAE;MACHH,EAAE,GAAGZ,OAAO,CAACY,EAAE,EAAEb,aAAa,CAAC,CAAC,CAAC,EAAEK,GAAG,CAACY,UAAU,CAACD,CAAC,GAAG,EAAE,CAAC,CAAC,EAAE,EAAE,CAAC,CAAC;IACpE,KAAK,EAAE;MACHH,EAAE,GAAGZ,OAAO,CAACY,EAAE,EAAEb,aAAa,CAAC,CAAC,CAAC,EAAEK,GAAG,CAACY,UAAU,CAACD,CAAC,GAAG,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC;IAClE,KAAK,CAAC;MACFH,EAAE,GAAGZ,OAAO,CAACY,EAAE,EAAE,CAAC,CAAC,EAAER,GAAG,CAACY,UAAU,CAACD,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC;MAC5CH,EAAE,GAAGf,YAAY,CAACe,EAAE,EAAEE,EAAE,CAAC;MACzBF,EAAE,GAAGd,QAAQ,CAACc,EAAE,EAAE,EAAE,CAAC;MACrBA,EAAE,GAAGf,YAAY,CAACe,EAAE,EAAEC,EAAE,CAAC;MACzBH,EAAE,GAAGV,OAAO,CAACU,EAAE,EAAEE,EAAE,CAAC;IACxB,KAAK,CAAC;MACFD,EAAE,GAAGX,OAAO,CAACW,EAAE,EAAEZ,aAAa,CAAC,CAAC,CAAC,EAAEK,GAAG,CAACY,UAAU,CAACD,CAAC,GAAG,CAAC,CAAC,CAAC,EAAE,EAAE,CAAC,CAAC;IACnE,KAAK,CAAC;MACFJ,EAAE,GAAGX,OAAO,CAACW,EAAE,EAAEZ,aAAa,CAAC,CAAC,CAAC,EAAEK,GAAG,CAACY,UAAU,CAACD,CAAC,GAAG,CAAC,CAAC,CAAC,EAAE,EAAE,CAAC,CAAC;IACnE,KAAK,CAAC;MACFJ,EAAE,GAAGX,OAAO,CAACW,EAAE,EAAEZ,aAAa,CAAC,CAAC,CAAC,EAAEK,GAAG,CAACY,UAAU,CAACD,CAAC,GAAG,CAAC,CAAC,CAAC,EAAE,EAAE,CAAC,CAAC;IACnE,KAAK,CAAC;MACFJ,EAAE,GAAGX,OAAO,CAACW,EAAE,EAAEZ,aAAa,CAAC,CAAC,CAAC,EAAEK,GAAG,CAACY,UAAU,CAACD,CAAC,GAAG,CAAC,CAAC,CAAC,EAAE,EAAE,CAAC,CAAC;IACnE,KAAK,CAAC;MACFJ,EAAE,GAAGX,OAAO,CAACW,EAAE,EAAEZ,aAAa,CAAC,CAAC,CAAC,EAAEK,GAAG,CAACY,UAAU,CAACD,CAAC,GAAG,CAAC,CAAC,CAAC,EAAE,EAAE,CAAC,CAAC;IACnE,KAAK,CAAC;MACFJ,EAAE,GAAGX,OAAO,CAACW,EAAE,EAAEZ,aAAa,CAAC,CAAC,CAAC,EAAEK,GAAG,CAACY,UAAU,CAACD,CAAC,GAAG,CAAC,CAAC,CAAC,EAAE,EAAE,CAAC,CAAC;IACnE,KAAK,CAAC;MACFJ,EAAE,GAAGX,OAAO,CAACW,EAAE,EAAEZ,aAAa,CAAC,CAAC,CAAC,EAAEK,GAAG,CAACY,UAAU,CAACD,CAAC,GAAG,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC;IAClE,KAAK,CAAC;MACFJ,EAAE,GAAGX,OAAO,CAACW,EAAE,EAAE,CAAC,CAAC,EAAEP,GAAG,CAACY,UAAU,CAACD,CAAC,CAAC,CAAC,CAAC;MACxCJ,EAAE,GAAGd,YAAY,CAACc,EAAE,EAAEE,EAAE,CAAC;MACzBF,EAAE,GAAGb,QAAQ,CAACa,EAAE,EAAE,EAAE,CAAC;MACrBA,EAAE,GAAGd,YAAY,CAACc,EAAE,EAAEG,EAAE,CAAC;MACzBL,EAAE,GAAGT,OAAO,CAACS,EAAE,EAAEE,EAAE,CAAC;EAAC;EAE7BF,EAAE,GAAGT,OAAO,CAACS,EAAE,EAAE,CAAC,CAAC,EAAEL,GAAG,CAACG,MAAM,CAAC,CAAC;EACjCG,EAAE,GAAGV,OAAO,CAACU,EAAE,EAAE,CAAC,CAAC,EAAEN,GAAG,CAACG,MAAM,CAAC,CAAC;EACjCE,EAAE,GAAGhB,OAAO,CAACgB,EAAE,EAAEC,EAAE,CAAC;EACpBA,EAAE,GAAGjB,OAAO,CAACiB,EAAE,EAAED,EAAE,CAAC;EACpBA,EAAE,GAAGR,QAAQ,CAACQ,EAAE,CAAC;EACjBC,EAAE,GAAGT,QAAQ,CAACS,EAAE,CAAC;EACjBD,EAAE,GAAGhB,OAAO,CAACgB,EAAE,EAAEC,EAAE,CAAC;EACpBA,EAAE,GAAGjB,OAAO,CAACiB,EAAE,EAAED,EAAE,CAAC;EACpB,OAAO,CAAC,UAAU,GAAG,CAACA,EAAE,CAAC,CAAC,CAAC,KAAK,CAAC,EAAEQ,QAAQ,CAAC,EAAE,CAAC,EAAEC,KAAK,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC,UAAU,GAAG,CAACT,EAAE,CAAC,CAAC,CAAC,KAAK,CAAC,EAAEQ,QAAQ,CAAC,EAAE,CAAC,EAAEC,KAAK,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC,UAAU,GAAG,CAACR,EAAE,CAAC,CAAC,CAAC,KAAK,CAAC,EAAEO,QAAQ,CAAC,EAAE,CAAC,EAAEC,KAAK,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC,UAAU,GAAG,CAACR,EAAE,CAAC,CAAC,CAAC,KAAK,CAAC,EAAEO,QAAQ,CAAC,EAAE,CAAC,EAAEC,KAAK,CAAC,CAAC,CAAC,CAAC;AAChO;AACA;AACA;AACA;AACA;AACA;AACA,OAAO,SAASC,OAAO,CAACC,GAAG,EAAEf,IAAI,EAAE;EAC/B,OAAOF,UAAU,CAACX,WAAW,CAAC4B,GAAG,CAAC,EAAEf,IAAI,KAAK,CAAC,CAAC;AACnD"},"metadata":{},"sourceType":"module"}